{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0Z7pb2vbIWg"
   },
   "source": [
    "# Урок 5. Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**План занятия**\n",
    "\n",
    "* [Теоретическая часть](#theory)\n",
    "    * [Разложения ошибки на смещение и разброс](#bias_variance)\n",
    "    * [Алгоритм построения случайного леса](#alg)\n",
    "        * [Out-of-Bag](#oob)\n",
    "    * [Реализация случайного леса](#implement)\n",
    "* [Домашнее задание](#hw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Теоретическая часть<a class=\"anchor\" id=\"theory\"></a><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzsNk_uYbIWj"
   },
   "source": [
    "Данный урок будет своеобразным логическим продолжением предыдущего. Основным недостатком деревьев решений является их склонность к переобучению и тот факт, что даже при небольшом изменении обучающей выборки дерево может значительно измениться. Однако их объединение в _ансамбли_ или _композиции_ на практике дает очень хорошие результаты. Ансамбли - это методы, сочетающие в себе несколько алгоритмов машинного обучения для получения более мощной модели. \n",
    "\n",
    "В случае задачи регрессии при использовании композиции $a(x)$ из $N$ _базовых алгоритмов_ $b_{n}(x)$ ответом будет считаться среднее значение ответа каждого алгоритма\n",
    "\n",
    "$$a(x) = \\frac{1}{N}\\sum_{n=1}^{N}b_{n}(x),$$\n",
    "\n",
    "в задачах классификации, соответственно, знак полученного усредненного ответа или (что аналогично) класс определяется путем _голосования_: объект относится к классу, за который \"проголосовало\" наибольшее число базовых алгоритмов.\n",
    "\n",
    "Одни из самых хорошо зарекомендовавших себя на практике решения задач классификации и регрессии с использованием деревьев решения - это _случайные леса_ и _градиентный бустинг_. В этом уроке пойдет речь о первом методе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/rf_explained.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разложения ошибки на смещение и разброс<a class='anchor' id='bias_variance'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2TEx7wFbIWl"
   },
   "source": [
    "Известно, что ошибка алгоритмов складывается из _смещения (bias)_ (отклонение среднего ответа обученного алгоритма от ответа идеального алгоритма) и _разброса_ или _дисперсии (variance)_ (разброс ответов обученных алгоритмов отнисительно среднего ответа). Также к этому разложению обычно прибавляется *шум*, который характеризует ошибку идеального алгоритма и которым никак нельзя управлять - это характеристика входных данных. Как правило, простые семейства алгоритмов (например, линейные классификаторы) характеризуются высоким смещением и низким разбросом, а сложные семейства (в т.ч. деревья) наоборот - низким смещением и высоким разбросом. Можно сказать, что разброс характеризует чувствительность метода обучения к выборке, то есть насколько будет изменяться ответ обученного алгоритма в зависимости от изменений в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Ошибка на новых данных = Шум + Смещение + Разброс, где</center>\n",
    "\n",
    "ШУМ - ошибка лучшей модели a(x)\n",
    "\n",
    "СМЕЩЕНИЕ - отклонение усредненных ответов наших моделей от ответов лучшей модели a(x)\n",
    "\n",
    "РАЗБРОС - дисперсия ответов наших моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Прдемонстрируем низкое смещение (bias) и большой разброс (variance)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 6 - 13 * x - 5 * x ** 2 - 4 * x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dots = np.linspace(-10, 10, 100)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.ylim(-5000, 5000)\n",
    "plt.xlim(-10, 10)\n",
    "\n",
    "plt.plot(dots, f(dots), color='g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_datas = []\n",
    "f_datas = []\n",
    "\n",
    "for i in range(10):\n",
    "    x_data = np.random.uniform(-10, 10, 25)\n",
    "    x_datas.append(x_data)\n",
    "    f_datas.append([f(i) for i in x_data] + np.random.uniform(-500, 500, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.ylim(-5000, 5000)\n",
    "plt.xlim(-10,10)\n",
    "\n",
    "plt.plot(dots, f(dots), color='g')\n",
    "plt.scatter(x_datas[1], f_datas[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regressors = []\n",
    "for i in range(10):\n",
    "    # создадим модель\n",
    "    regressor = DecisionTreeRegressor(max_depth=10)\n",
    "    # обучим ее\n",
    "    regressor.fit(np.reshape(x_datas[i], (-1, 1)), f_datas[i])\n",
    "    regressors.append(regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.ylim(-5000, 5000)\n",
    "plt.xlim(-10, 10)\n",
    "\n",
    "predictions = []\n",
    "for i in range(10):\n",
    "    plt.plot(dots, f(dots), color='g')\n",
    "    plt.scatter(x_datas[i], f_datas[i])\n",
    "    prediction = regressors[i].predict(np.reshape(dots, (-1, 1)))\n",
    "    predictions.append(prediction)\n",
    "    plt.plot(dots, prediction, color='r');\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_prediction = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.ylim(-5000, 5000)\n",
    "plt.xlim(-10,10)\n",
    "\n",
    "plt.plot(dots, f(dots), color='g')\n",
    "plt.plot(dots, mean_prediction, color='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Прдемонстрируем высокое смещение (bias) и низкий разброс (variance)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots = np.linspace(-10, 10, 100)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.ylim(-5000, 5000)\n",
    "plt.xlim(-10,10)\n",
    "\n",
    "plt.plot(dots, f(dots), color='g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressors = []\n",
    "for i in range(10):\n",
    "    # создадим модель\n",
    "    regressor = LinearRegression()\n",
    "    \n",
    "    # обучим ее\n",
    "    regressor.fit(np.reshape(x_datas[i], (-1, 1)), f_datas[i])\n",
    "    regressors.append(regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.ylim(-5000, 5000)\n",
    "plt.xlim(-10, 10)\n",
    "\n",
    "predictions = []\n",
    "for i in range(10):\n",
    "    plt.plot(dots, f(dots), color='g')\n",
    "    plt.scatter(x_datas[i], f_datas[i])\n",
    "    prediction = regressors[i].predict(np.reshape(dots, (-1, 1)))\n",
    "    predictions.append(prediction)\n",
    "    plt.plot(dots, prediction, color='r');\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_prediction = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.ylim(-5000, 5000)\n",
    "plt.xlim(-10, 10)\n",
    "\n",
    "plt.plot(dots, f(dots), color='g')\n",
    "plt.plot(dots, mean_prediction, color='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Усреднение алгоритмов:**\n",
    "\n",
    "- Не меняется смещение\n",
    "\n",
    "- Разброс = $\\frac{\\text {разброс базового алгоритма}}{N} + \\text {корреляция между базовыми алгоритмами}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть два подхода, позволяющих уменьшить корреляцию: \n",
    "\n",
    "* _бэггинг_ (обучение базовых алгоритмов на случайной подвыборке),\n",
    "* _метод случайных подпространств_ (обучение базовых алгоритмов на случайном подмножестве признаков) или их комбинация. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzZc-SKFbIWk"
   },
   "source": [
    "**Бутстрап**\n",
    "\n",
    "Случайные леса названы так из-за того, что в процесс построения деревьев, из которых они состоят, внесен элемент случайности для обеспечения уникальности каждого из деревьев. Такая рандомизация заключается в обучении базовых алгоритмов на разных подвыборках обучающей выборки. Один из способов построения случайных подвыборок - _бутстрап (bootstrap)_. Этот метод заключается в получении из выборки длины $l$ нескольких разных выборок той же длины $l$. Для получения бутстрап-выборки из исходной выборки $l$ раз выбирается случайный элемент, причем каждый раз новый элемент выбирается из всей выборки. Таким образом, в полученной в конечном итоге бутстрап-выборке некоторые элементы исходной выборки будут встречаться несколько раз, а некоторые (примерно 37% выборки) будут вовсе отсутствовать, и при повторении $N$ раз мы получим $N$ разных выборок длиной $l$. Например, если у нас есть исходная выборка вида [a, b, c, d, e], возможными бутстрап-выборками могут быть [a, b, a, c, b] или [b, e, e, d, b] и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/bootstrap.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Бэггинг__\n",
    "\n",
    "<img src=\"images/Bagging.png\" width=700px>\n",
    "\n",
    "__Метод случайных подпространств__\n",
    "\n",
    "<img src=\"images/Random_Subspaces.png\" width=700px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3nwuz1cbIWn"
   },
   "source": [
    "## Алгоритм построения случайного леса <a class='anchor' id='alg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZVn9sXDbIWo"
   },
   "source": [
    "При построении случайного леса вначале генерируется количество бутстрап-выборок, равное количеству деревьев в алгоритме. Для уменьшения корреляции базовых алгоритмов рандомизируют сам процесс построения каждого дерева: если в стандартном методе построения деревьев мы в каждом узле выбираем $j$-й признак и порог $t$, с которым сравнивается его значение, и потом эти значения оптимизируются с помощью функции ошибки, то в методе случайного леса в каждой вершине $j$-й признак выбирается не из всего пространства признаков, а из его случайного подмножества размера $m$, __которое каждый раз выбирается заново__ (в этом отличие от метода случайных подпространств, где подпространство выбирается единожды и используется для построения всего дерева). \n",
    "\n",
    "Есть некоторые практически рекомендации по построению случайных лесов: в задачах классификации рекомендуется брать $m = \\sqrt{d}$, где $d$ - общее число признаков, и строить дерево до тех пор, пока в каждом листе не останется по одному объекту, а в задаче регрессии принимать $m = d/3$ и строить дерево, пока в листьях не останется по пять объектов.\n",
    "\n",
    "Далее построенные деревья объединяются в композицию, и при предсказаниях с его помощью используется усредненный ответ на каждом дереве."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Random_Forest.png\" width=600px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cr-tqx0obIWo"
   },
   "source": [
    "### Out-of-Bag <a class='anchor' id='oob'>\n",
    "[Пример из sklearn](https://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html) по OOB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5l2JelGebIWp"
   },
   "source": [
    "Вспомним, что каждое дерево $b_{n}$, составляющее случайный лес, строится на основе бутстрапированной выборки $X_{n}$. При этом примерно 37% объектов не попадают в эту выборку, и дерево на них не обучается. Эти объекты можно использовать для оценки качества полученного алгоритма, это и называется _out-of-bag error_. Для каждог объекта $x_{i}$ мы можем найти деревья, которые на нем не обучались, и вычислить ошибку: она рассчитывается как сумма значений ошибки для среднего ответа на каждом объекте $x_{i}$ среди деревьев, которые на нем не обучались:\n",
    "\n",
    "$$OOB = \\sum^{l}_{i=1}L\\left ( y_{i}, \\:\\frac{1}{\\sum^{N}_{n=1}[x_{i}\\notin X_{n}]} \\sum^{N}_{n=1}[x_{i} \\notin X_{n}]b_{n}(x_{i}) \\right ).$$\n",
    "\n",
    "Здесь $L(y, z)$ - функция потерь, а выражение в скобках и представляет из себя среднюю ошибку на объекте $x_{i}$ среди деревьев, которые на нем не обучались."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysV5Pa5PbIWq"
   },
   "source": [
    "При использовании этого метода оценивания качества исчезает необходимость использовать отложенные выборки и кросс-валидацию при обучении случайных лесов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQJYSrtPbIWr"
   },
   "source": [
    "## Реализация случайного леса <a class='anchor' id='implement'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXXt8ZpAbIWs"
   },
   "source": [
    "Для лучшего понимания алгоритма построения случайного леса реализуем его на Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNR-FOeobIWs"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4Mb7omZbIWw"
   },
   "outputs": [],
   "source": [
    "# сгенерируем данные, представляющие собой 500 объектов с 5-ю признаками\n",
    "classification_data, classification_labels = make_classification(n_samples=500,\n",
    "                                                                 n_features=5, n_informative=5, \n",
    "                                                                 n_classes=2, n_redundant=0, \n",
    "                                                                 n_clusters_per_class=1, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "2R53TJClbIWz",
    "outputId": "b9907394-fa3f-4b69-b2ef-28fcbf0bb8b2"
   },
   "outputs": [],
   "source": [
    "# визуализируем сгенерированные данные\n",
    "\n",
    "colors = ListedColormap(['red', 'blue'])\n",
    "light_colors = ListedColormap(['lightcoral', 'lightblue'])\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(classification_data[:, 0], classification_data[:, 1], \n",
    "              c=classification_labels, cmap=colors);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvjWiryZbIW2"
   },
   "source": [
    "Реализуем генерацию $N$ бутстрап-выборок и подмножества признаков для нахождения разбиения в узле."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7if4ogqbIW3"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def get_bootstrap(data, labels, N):\n",
    "    n_samples = data.shape[0] # размер совпадает с исходной выборкой\n",
    "    bootstrap = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        sample_index = np.random.randint(0, n_samples, size=n_samples)\n",
    "        b_data = data[sample_index]\n",
    "        b_labels = labels[sample_index]\n",
    "        \n",
    "        bootstrap.append((b_data, b_labels))\n",
    "        \n",
    "    return bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_bootstrap(classification_data, classification_labels, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "526l0aGNbIW5"
   },
   "outputs": [],
   "source": [
    "def get_subsample(len_sample):\n",
    "    # будем сохранять не сами признаки, а их индексы\n",
    "    sample_indexes = list(range(len_sample))\n",
    "\n",
    "    len_subsample = int(np.sqrt(len_sample))\n",
    "    \n",
    "    subsample = np.random.choice(sample_indexes, size=len_subsample, replace=False)\n",
    "\n",
    "    return subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_subsample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9ZdDJGvbIW8"
   },
   "source": [
    "Далее повторим реализацию построения дерева решений из предыдущего урока с некоторыми изменениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Duu45IJUabXi"
   },
   "outputs": [],
   "source": [
    "# Реализуем класс узла\n",
    "\n",
    "class Node:\n",
    "    \n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
    "        self.t = t  # значение порога\n",
    "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
    "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QY8oNtakabXl"
   },
   "outputs": [],
   "source": [
    "# И класс терминального узла (листа)\n",
    "\n",
    "class Leaf:\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.prediction = self.predict()\n",
    "        \n",
    "    def predict(self):\n",
    "        # подсчет количества объектов разных классов\n",
    "        classes = {}  # сформируем словарь \"класс: количество объектов\"\n",
    "        for label in self.labels:\n",
    "            if label not in classes:\n",
    "                classes[label] = 0\n",
    "            classes[label] += 1\n",
    "            \n",
    "        # найдем класс, количество объектов которого будет максимальным в этом листе и вернем его    \n",
    "        prediction = max(classes, key=classes.get)\n",
    "        return prediction        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uBdli3WDabXn"
   },
   "outputs": [],
   "source": [
    "# Расчет критерия Джини\n",
    "\n",
    "def gini(labels):\n",
    "    #  подсчет количества объектов разных классов\n",
    "    classes = {}\n",
    "    for label in labels:\n",
    "        if label not in classes:\n",
    "            classes[label] = 0\n",
    "        classes[label] += 1\n",
    "    \n",
    "    #  расчет критерия\n",
    "    impurity = 1\n",
    "    for label in classes:\n",
    "        p = classes[label] / len(labels)\n",
    "        impurity -= p ** 2\n",
    "        \n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vvLDhuRabXr"
   },
   "outputs": [],
   "source": [
    "# Расчет прироста\n",
    "\n",
    "def gain(left_labels, right_labels, root_gini):\n",
    "\n",
    "    # доля выборки, ушедшая в левое поддерево\n",
    "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "    \n",
    "    return root_gini - p * gini(left_labels) - (1 - p) * gini(right_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhWkphi3abXt"
   },
   "outputs": [],
   "source": [
    "# Разбиение датасета в узле\n",
    "\n",
    "def split(data, labels, column_index, t):\n",
    "    \n",
    "    left = np.where(data[:, column_index] <= t)\n",
    "    right = np.where(data[:, column_index] > t)\n",
    "        \n",
    "    true_data = data[left]\n",
    "    false_data = data[right]\n",
    "    \n",
    "    true_labels = labels[left]\n",
    "    false_labels = labels[right]\n",
    "        \n",
    "    return true_data, false_data, true_labels, false_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wi8Fbs_abXw"
   },
   "outputs": [],
   "source": [
    "# Нахождение наилучшего разбиения\n",
    "\n",
    "def find_best_split(data, labels):\n",
    "    \n",
    "    #  обозначим минимальное количество объектов в узле\n",
    "    min_leaf_samples = 5\n",
    "\n",
    "    root_gini = gini(labels)\n",
    "\n",
    "    best_gain = 0\n",
    "    best_t = None\n",
    "    best_index = None\n",
    "    \n",
    "    n_features = data.shape[1]\n",
    "    \n",
    "    feature_subsample_indices = get_subsample(n_features) # выбираем случайные признаки\n",
    "    \n",
    "    for index in feature_subsample_indices:\n",
    "        # будем проверять только уникальные значения признака, исключая повторения\n",
    "        t_values = np.unique(data[:, index])\n",
    "        \n",
    "        for t in t_values:\n",
    "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "            #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
    "            if len(true_data) < min_leaf_samples or len(false_data) < min_leaf_samples:\n",
    "                continue\n",
    "            \n",
    "            current_gain = gain(true_labels, false_labels, root_gini)\n",
    "            \n",
    "            #  выбираем порог, на котором получается максимальный прирост качества\n",
    "            if current_gain > best_gain:\n",
    "                best_gain, best_t, best_index = current_gain, t, index\n",
    "\n",
    "    return best_gain, best_t, best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1__qSXSabXy"
   },
   "outputs": [],
   "source": [
    "# Построение дерева с помощью рекурсивной функции\n",
    "\n",
    "def build_tree(data, labels):\n",
    "\n",
    "    gain, t, index = find_best_split(data, labels)\n",
    "\n",
    "    #  Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
    "    if gain == 0:\n",
    "        return Leaf(data, labels)\n",
    "\n",
    "    true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "\n",
    "    # Рекурсивно строим два поддерева\n",
    "    true_branch = build_tree(true_data, true_labels)\n",
    "    false_branch = build_tree(false_data, false_labels)\n",
    "\n",
    "    # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "    return Node(index, t, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_YX8fnmbIXU"
   },
   "source": [
    "Теперь добавим функцию формирования случайного леса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZMieMMrbIXV"
   },
   "outputs": [],
   "source": [
    "def random_forest(data, labels, n_trees):\n",
    "    forest = []\n",
    "    bootstrap = get_bootstrap(data, labels, n_trees)\n",
    "    \n",
    "    for b_data, b_labels in bootstrap:\n",
    "        forest.append(build_tree(b_data, b_labels))\n",
    "        \n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWNbZTz4bIXX"
   },
   "outputs": [],
   "source": [
    "# Функция классификации отдельного объекта\n",
    "\n",
    "def classify_object(obj, node):\n",
    "\n",
    "    #  Останавливаем рекурсию, если достигли листа\n",
    "    if isinstance(node, Leaf):\n",
    "        answer = node.prediction\n",
    "        return answer\n",
    "\n",
    "    if obj[node.index] <= node.t:\n",
    "        return classify_object(obj, node.true_branch)\n",
    "    else:\n",
    "        return classify_object(obj, node.false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rWOM8g_YbIXZ"
   },
   "outputs": [],
   "source": [
    "# функция формирования предсказания по выборке на одном дереве\n",
    "\n",
    "def predict(data, tree):\n",
    "    \n",
    "    classes = []\n",
    "    for obj in data:\n",
    "        prediction = classify_object(obj, tree)\n",
    "        classes.append(prediction)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtIgR7R-bIXc"
   },
   "outputs": [],
   "source": [
    "# предсказание голосованием деревьев\n",
    "\n",
    "def tree_vote(forest, data):\n",
    "\n",
    "    # добавим предсказания всех деревьев в список\n",
    "    predictions = []\n",
    "    for tree in forest:\n",
    "        predictions.append(predict(data, tree))\n",
    "#     print(predictions)\n",
    "\n",
    "    # сформируем список с предсказаниями для каждого объекта\n",
    "    predictions_per_object = list(zip(*predictions))\n",
    "#     print(predictions_per_object)\n",
    "\n",
    "    # выберем в качестве итогового предсказания для каждого объекта то,\n",
    "    # за которое проголосовало большинство деревьев\n",
    "    voted_predictions = []\n",
    "    for obj in predictions_per_object:\n",
    "        voted_predictions.append(max(set(obj), key=obj.count))\n",
    "        \n",
    "    return voted_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_vote(my_forest_3, test_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkMTjBewbIXf"
   },
   "source": [
    "Далее мы сделаем обычное разбиение выборки на обучающую и тестовую, как это делалось ранее. Оценить ошибку этого же алгоритма по методу Out-of-Bag будет вашим домашним заданием к этому уроку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ie9t9IyAbIXh"
   },
   "outputs": [],
   "source": [
    "# Разобьем выборку на обучающую и тестовую\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(classification_data, \n",
    "                                                                    classification_labels, \n",
    "                                                                    test_size=0.3,\n",
    "                                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4apOFB9bIXk"
   },
   "outputs": [],
   "source": [
    "# Введем функцию подсчета точности как доли правильных ответов\n",
    "\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7ZzmLcNbIXn"
   },
   "source": [
    "Теперь построим несколько случайных лесов с разным количеством деревьев в них."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dcd1Jw6HbIXo"
   },
   "source": [
    "Построим лес из одного дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ie4loVA2bIXp"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "n_trees = 1\n",
    "my_forest_1 = random_forest(train_data, train_labels, n_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jlpOoeyNbIXr"
   },
   "outputs": [],
   "source": [
    "# Получим ответы для обучающей выборки \n",
    "train_answers = tree_vote(my_forest_1, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dh7KkPTUbIXt"
   },
   "outputs": [],
   "source": [
    "# И получим ответы для тестовой выборки\n",
    "test_answers = tree_vote(my_forest_1, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "2AVq8YUqbIXv",
    "outputId": "241785cc-ac19-410a-ba06-5e399ea6db98"
   },
   "outputs": [],
   "source": [
    "# Точность на обучающей выборке\n",
    "train_accuracy = accuracy_metric(train_labels, train_answers)\n",
    "print(f'Точность случайного леса из {n_trees} деревьев на обучающей выборке: {train_accuracy:.3f}')\n",
    "\n",
    "# Точность на тестовой выборке\n",
    "test_accuracy = accuracy_metric(test_labels, test_answers)\n",
    "print(f'Точность случайного леса из {n_trees} деревьев на тестовой выборке: {test_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHSLxUfXbIX1"
   },
   "source": [
    "Построим лес из трех деревьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JEfTGC08bIX2"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "n_trees = 3\n",
    "my_forest_3 = random_forest(train_data, train_labels, n_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7k6rZW6bIX4"
   },
   "outputs": [],
   "source": [
    "# Получим ответы для обучающей выборки \n",
    "train_answers = tree_vote(my_forest_3, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvROZSabbIX6"
   },
   "outputs": [],
   "source": [
    "# И получим ответы для тестовой выборки\n",
    "test_answers = tree_vote(my_forest_3, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "m3H-p2RhbIX8",
    "outputId": "447c7d28-2c2f-4db8-e410-b4bee80a4eff"
   },
   "outputs": [],
   "source": [
    "# Точность на обучающей выборке\n",
    "train_accuracy = accuracy_metric(train_labels, train_answers)\n",
    "print(f'Точность случайного леса из {n_trees} деревьев на обучающей выборке: {train_accuracy:.3f}')\n",
    "\n",
    "# Точность на тестовой выборке\n",
    "test_accuracy = accuracy_metric(test_labels, test_answers)\n",
    "print(f'Точность случайного леса из {n_trees} деревьев на тестовой выборке: {test_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfcvqNmabIYA"
   },
   "source": [
    "Построим лес из десяти деревьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4W9ZyefbIYB"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "n_trees = 10\n",
    "my_forest_10 = random_forest(train_data, train_labels, n_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_aF8gd-bIYC"
   },
   "outputs": [],
   "source": [
    "# Получим ответы для обучающей выборки \n",
    "train_answers = tree_vote(my_forest_10, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5D5_gy33bIYG"
   },
   "outputs": [],
   "source": [
    "# И получим ответы для тестовой выборки\n",
    "test_answers = tree_vote(my_forest_10, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "7Fsqi2OdbIYI",
    "outputId": "572e833b-abc3-435f-ee49-abb01d9d2f60"
   },
   "outputs": [],
   "source": [
    "# Точность на обучающей выборке\n",
    "train_accuracy = accuracy_metric(train_labels, train_answers)\n",
    "print(f'Точность случайного леса из {n_trees} деревьев на обучающей выборке: {train_accuracy:.3f}')\n",
    "\n",
    "# Точность на тестовой выборке\n",
    "test_accuracy = accuracy_metric(test_labels, test_answers)\n",
    "print(f'Точность случайного леса из {n_trees} деревьев на тестовой выборке: {test_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fa3cUkrLbIYP"
   },
   "source": [
    "Построим лес из пятидесяти деревьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DNvHGqmLbIYQ"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "n_trees = 500\n",
    "my_forest_50 = random_forest(train_data, train_labels, n_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SgvItR0gbIYR"
   },
   "outputs": [],
   "source": [
    "# Получим ответы для обучающей выборки \n",
    "train_answers = tree_vote(my_forest_50, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZlGAMHlibIYT"
   },
   "outputs": [],
   "source": [
    "# И получим ответы для тестовой выборки\n",
    "test_answers = tree_vote(my_forest_50, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "vXbLxcn7bIYV",
    "outputId": "a9c8eb61-5970-4d1e-993a-84780c195b49"
   },
   "outputs": [],
   "source": [
    "# Точность на обучающей выборке\n",
    "train_accuracy = accuracy_metric(train_labels, train_answers)\n",
    "print(f'Точность случайного леса из {n_trees} деревьев на обучающей выборке: {train_accuracy:.3f}')\n",
    "\n",
    "# Точность на тестовой выборке\n",
    "test_accuracy = accuracy_metric(test_labels, test_answers)\n",
    "print(f'Точность случайного леса из {n_trees} деревьев на тестовой выборке: {test_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjdGUi1mbIYc"
   },
   "source": [
    "Как можно увидеть из показателей качества предсказаний, точность случайного леса возрастает при увеличении числа деревьев в нем. При этом по точности на тестовой выборке можно сказать, что при увеличении количества деревьев до 50 наш лес не переобучается. Это одна из основных особенностей случайного леса - он редко переобучается при увеличении числа базовых алгоритмов, а ошибка выходит на асимптоту."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание<a class='anchor' id='hw'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Сформировать с помощью sklearn.make_classification датасет из 100 объектов с двумя признаками, обучить случайный лес из 1, 3, 10 и 50 деревьев и визуализировать их разделяющие гиперплоскости на графиках (по подобию визуализации деревьев из предыдущего урока, необходимо только заменить вызов функции predict на tree_vote).\n",
    "2. Сделать выводы о получаемой сложности гиперплоскости и недообучении или переобучении случайного леса в зависимости от количества деревьев в нем.\n",
    "\n",
    "3. *Заменить в реализованном алгоритме проверку с помощью отложенной выборки на Out-of-Bag.\n",
    "\n",
    "4. *(На повторение) Переписать функцию gini из урока про решающие деревья так, чтобы в качестве критерия использовалась энтропия Шэннона. Переименовать функцию в entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проект: \n",
    "1. https://www.kaggle.com/c/regression-tutors-expected-math-exam-results регрессия\n",
    "1. https://www.kaggle.com/c/classification-choose-tutors классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCkVGRl6bIYc"
   },
   "source": [
    "## Дополнительные материалы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f6YYzgUwbIYd"
   },
   "source": [
    "1. [Смещение и разброс](https://dyakonov.org/2018/04/25/%D1%81%D0%BC%D0%B5%D1%89%D0%B5%D0%BD%D0%B8%D0%B5-bias-%D0%B8-%D1%80%D0%B0%D0%B7%D0%B1%D1%80%D0%BE%D1%81-variance-%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8-%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82/)\n",
    "2. [Бэггинг с точки зрения статистики](https://habr.com/ru/company/ods/blog/324402/#begging)\n",
    "3. [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n",
    "4. [Случайный лес (Random Forest)](https://dyakonov.org/2016/11/14/%D1%81%D0%BB%D1%83%D1%87%D0%B0%D0%B9%D0%BD%D1%8B%D0%B9-%D0%BB%D0%B5%D1%81-random-forest/)\n",
    "5. [Реализация и разбор алгоритма «случайный лес» на Python](https://tproger.ru/translations/python-random-forest-implementation/)\n",
    "6. [Прикладные задачи анализа данных. Случайные леса](http://www.machinelearning.ru/wiki/images/c/cc/PZAD2016_09_rf.pdf)\n",
    "7. Андреас Мюллер, Сара Гвидо, Введение в машинное обучение с помощью Python. Руководство для специалистов по работе с данными (2016)\n",
    "8. [Пример из sklearn](https://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html) по OOB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Случайноый лес__\n",
    "\n",
    "* Один из сильнейших “классических\" алгоритмов машинного обучения\n",
    "* Не требователен к обучающей выборке (не требуется нормализация, очистка от шума, ...) \n",
    "* Легко параллелится, так как базовые модели обучаются независимо друг от друга\n",
    "* Слабо подвержен переобучению \n",
    "* Дает оценку важности признаков (feature importance)\n",
    "* Не требует дополнительной валидационной выборки (за счет OOB-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определения\n",
    "*Композиции*\n",
    "\n",
    "**Ансамбли** — это методы, сочетающие в себе несколько алгоритмов машинного обучения для получения более мощной модели.\n",
    "\n",
    "**Бутстрап (bootstrap)** — метод сэмплирования подвыборки. Заключается в получении из выборки длины  𝑙  нескольких разных выборок той же длины  𝑙.\n",
    "\n",
    "**Бэггинг** — обучение базовых алгоритмов на случайной подвыборке.\n",
    "\n",
    "**Метод случайных подпространств** — обучение базовых алгоритмов на случайном подмножестве признаков или их комбинация. \n",
    "\n",
    "*Разложение ошибки*\n",
    "\n",
    "**Смещение (bias)** — отклонение среднего ответа обученного алгоритма от ответа идеального алгоритма.\n",
    "\n",
    "**Разброс или дисперсии (variance)** — разброс ответов обученных алгоритмов отнисительно среднего ответа.\n",
    "\n",
    "**Шум** — ошибка идеального алгоритма, характеристика входных данных.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lesson_5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
